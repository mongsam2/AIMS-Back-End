import os

from celery import shared_task
from django.conf import settings
from .models import Documentation, Document, DocumentType, DocumentStateChoices

from aims.models import Extraction, ExtractionEssay
from aims.tasks import execute_ocr, get_answer_from_solar

import torch
import numpy as np
from aims_be.documents.utils.load_model import load_pytorch_model
from aims_be.documents.utils.load_model import load_onnx_model

from documents.utils.data_loader import preprocess_image


@shared_task
def process_ocr_task(document_id, api_key):
    """
    ë¹„ë™ê¸° OCR íƒœìŠ¤í¬
    """
    try:
        document = Documentation.objects.get(id=document_id)
        content, confidence = execute_ocr(api_key, document.file_url.path)
        Extraction.objects.create(content=content, document=document)
            
    except Documentation.DoesNotExist:
        raise ValueError(f"Document with ID {document_id} does not exist")
    except Exception as e:
        raise ValueError(f"Error processing OCR for Document ID {document_id}: {str(e)}")


@shared_task
def process_ocr_task_for_essay(document_id, api_key):
    """
    ë¹„ë™ê¸° OCR íƒœìŠ¤í¬
    """
    try:
        document = Document.objects.get(id=document_id)
        content, confidence = execute_ocr(api_key, document.file_url.path)
        
        threshold = 0.8

        # OCR ì¸ì‹ë¥  ì €í•˜ ì‹œ ê²½ê³  ë©”ì‹œì§€ ì €ì¥
        if confidence <= threshold:
            warning = f'ê²½ê³ : OCR ì‹ ë¢°ë„ê°€ ë‚®ìŠµë‹ˆë‹¤ ({confidence:.2f}). í…ìŠ¤íŠ¸ê°€ ë¶€ì •í™•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n'
            ExtractionEssay.objects.create(content=warning, document=document)
        else:
            prompt_path = os.path.join(settings.BASE_DIR, 'aims', 'utils', 'prompt_txt', 'refine_prompt.txt')
            with open(prompt_path, 'r', encoding='utf-8') as f:
                prompt = f.read()

            refined_content = get_answer_from_solar(api_key, content, prompt)
            ExtractionEssay.objects.create(content=refined_content, document=document)
            
    except Document.DoesNotExist:
        raise ValueError(f"Document with ID {document_id} does not exist")
    except Exception as e:
        raise ValueError(f"Error processing OCR for Document ID {document_id}: {str(e)}")


@shared_task
def process_inference(document_id):
    """
    ë¹„ë™ê¸° inference ì‘ì—… ìˆ˜í–‰

    Args:
        document_id (Documentation): Documentation í…Œì´ë¸”ì˜ ì¸ìŠ¤í„´ìŠ¤
    """
    try:
        document = Documentation.objects.get(id=document_id)
        class_labels = settings.LABELS
        
        d_type, confidence = predict_document_type(document.file_url.path, class_labels)
        #d_type, confidence = predict_onnx(document.file_url.path, class_labels)

        matched_document_type = DocumentType.objects.filter(name=d_type).first()

        if matched_document_type:
            document.document_type = matched_document_type.name
            document.state = DocumentStateChoices.ì œì¶œ
            document.save()
            print(f"ğŸŸ¢ ë¬¸ì„œ {document_id}ì˜ ìœ í˜•ì´ '{matched_document_type}'ë¡œ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            document.state = DocumentStateChoices.ê²€í† 
            document.save()
            print(f"ğŸŸ¡ ë¬¸ì„œ {document_id}: '{d_type}'ë¥¼ DocumentTypeì—ì„œ ì°¾ì„ ìˆ˜ ì—†ì–´ ìƒíƒœë¥¼ 'ê²€í† 'ë¡œ ë³€ê²½.")

        return f"Inference ì„±ê³µ: ë¬¸ì„œ {document_id} â†’ {matched_document_type if matched_document_type else 'ê²€í† '}"

    except Documentation.DoesNotExist:
        return f"ë¬¸ì„œ {document_id}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    except Exception as e:
        return f"Inference ì‹¤íŒ¨: {str(e)}"
    

@shared_task
def predict_document_type(file_path, class_labels):
    
    model = load_pytorch_model()
    model.eval()

    image = preprocess_image(file_path)
    
    with torch.no_grad():
        output = model(image)
        probabilities = torch.nn.functional.softmax(output, dim=1)
        predicted_class = torch.argmax(probabilities, dim=1).item()

    predicted_label = class_labels[predicted_class]
    confidence = probabilities[0][predicted_class].item()
    
    return predicted_label, confidence


@shared_task
def predict_onnx(image_path, class_labels):
    
    session = load_onnx_model()
    image = preprocess_image(image_path)
    
    inputs = {session.get_inputs()[0].name: image}
    output = session.run(None, inputs)[0]

    predicted_class = np.argmax(output, axis=1).item()
    confidence = np.max(output).item()

    return class_labels[predicted_class], confidence